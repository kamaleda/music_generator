{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d2843f",
   "metadata": {},
   "source": [
    "This file takes the 92 .MIDI files and converts them to a multi-hot encoded array for input into the NN models\n",
    "The library, music21 is primarily used, Documentation http://web.mit.edu/music21/doc/index.html\n",
    "*NOTE* music21 could not process some midi files. The midi files were batch converted to .mxl format using MuseScore 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6c0e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from music21 import stream,note,chord,converter,instrument\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb930e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set pandas display options\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad0edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first two piano parts of each song\n",
    "def getPiano(loaded_song):\n",
    "    # Gets elements of loaded song that are \"Parts\"\n",
    "    parts = loaded_song.getElementsByClass(\"Part\")\n",
    "    strm_prts = []\n",
    "    i=0\n",
    "    \n",
    "    # Store only the first 2 parts of each song\n",
    "    for p in parts:\n",
    "        if isinstance(p.getInstrument(), instrument.Piano):\n",
    "            if(i<2):\n",
    "                strm_prts.append(p)\n",
    "                i+=1\n",
    "    # Append parts into a music \"Stream\", and flatten\n",
    "    strm = stream.Score(strm_prts)\n",
    "    piano_parts = strm.flatten()\n",
    "    \n",
    "    # Store only notes and chords (ignore time signatures, measures, etc..)\n",
    "    piano_parts = piano_parts.getElementsByClass([\"Note\",\"Chord\"])\n",
    "    return piano_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbb8fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store notes/chords in numpy array with 1/16 beat uniform time step\n",
    "def splitToTimesteps(piano_parts):\n",
    "    #Initialize array: \n",
    "    #First col is timesteps\n",
    "    #Second col is whether note is held or not (0 or 1)\n",
    "    #Third col is midi pitch of a note\n",
    "    step_array = np.empty((0,3))\n",
    "    \n",
    "    step_size = 0.0625\n",
    "    next_offset=0\n",
    "    for i in piano_parts:\n",
    "        # Check for notes that are not a factor of the timestep\n",
    "        # Round duration down to nearest timestep\n",
    "        if(i.offset%step_size>0):\n",
    "            i.offset = next_offset\n",
    "        if(i.quarterLength%step_size>0):\n",
    "            next_offset = i.offset+np.floor(i.quarterLength*16)/16\n",
    "        \n",
    "        #Split offsets into step_size increments\n",
    "        #If chord, split into individual notes of chord, and store at the same timesteps\n",
    "        if(i.isNote):\n",
    "            for j in np.arange(i.offset,i.offset+np.floor(i.quarterLength*16)/16,step_size):\n",
    "                if(j==i.offset):\n",
    "                    n_hold = 1 #Indicates a note on event\n",
    "                else:\n",
    "                    n_hold = 0 #Indicates a note is held\n",
    "                step_array = np.append(step_array,[[j,n_hold, i.pitch.midi]], axis = 0 )\n",
    "        elif (i.isChord):\n",
    "            for p in i.pitches:\n",
    "                for j in np.arange(i.offset,i.offset+np.floor(i.quarterLength*16)/16,step_size):\n",
    "                    if(j==i.offset):\n",
    "                        n_hold = 1 #Indicates a note on event\n",
    "                    else:\n",
    "                        n_hold = 0 #Indicates a note is held\n",
    "                    step_array = np.append(step_array,[[j,n_hold, p.midi]], axis = 0 )\n",
    "    return(step_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1ceb803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi hot encode notes \n",
    "def multiHotEncode(step_array):\n",
    "    # Using sklearn preprocessing library\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(np.arange(0,128,1).reshape(-1,1))\n",
    "    \n",
    "    # Take only the pitch column and one hot encode notes\n",
    "    midi_pitches = step_array[:,2].astype(int).reshape(-1,1)\n",
    "    encoded_pitches = enc.transform(midi_pitches).toarray()\n",
    "    \n",
    "    #Append encoded pitches to timesteps to create new encoded array\n",
    "    encoded_array = np.append(step_array[:,0:2], encoded_pitches, axis=1)\n",
    "\n",
    "    #https://numpy.org/doc/stable/reference/generated/numpy.nditer.html\n",
    "    #Replace 1s with -1 to indicate note is held\n",
    "    for row in encoded_array:\n",
    "        if row[1] == 0:\n",
    "            for cell in np.nditer(row[2:], flags = ['refs_ok'], op_flags=['readwrite']):\n",
    "                if cell > 0:\n",
    "                    cell[...] = -1.0\n",
    "\n",
    "    #Remove note on or hold column, not needed anymore\n",
    "    encoded_array = np.delete(encoded_array,1,axis=1)\n",
    "    \n",
    "    #Store encoded_array as a pandas dataframe\n",
    "    encoded_df = pd.DataFrame(encoded_array, columns = np.arange(-1,128,1))\n",
    "    encoded_df = encoded_df.rename(columns = {-1 : 'step'})\n",
    "    \n",
    "    #Sum rows with duplicate timestep to get notes played multi-hot representation\n",
    "    #https://stackoverflow.com/questions/68120846/how-to-combine-rows-that-have-the-same-values-in-two-columns-python\n",
    "    #https://stackoverflow.com/questions/27968028/add-row-with-duplicate-index-in-a-panda-dataframe\n",
    "    multihot_df = encoded_df.groupby(\"step\").sum().reset_index()\n",
    "    multihot_np = multihot_df.to_numpy()\n",
    "    return(multihot_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "371ca6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferRests(no_rests):\n",
    "    #Infer rests from lack of notes occurring to fill in missing timestamps\n",
    "    #Add zero row to indicate rest\n",
    "\n",
    "    #Create empty array for data\n",
    "    data = np.empty((0,129))\n",
    "\n",
    "    #Iterate through each row, check if difference between next row >timestep\n",
    "    #Then add number of timesteps of the difference\n",
    "    for row in range(no_rests.shape[0]):\n",
    "        data = np.append(data,no_rests[row].reshape(-1,129),axis=0)\n",
    "        if(row+1<no_rests.shape[0]):\n",
    "            if(no_rests[row+1,0]-no_rests[row,0]>0.0625):\n",
    "                n = int((no_rests[row+1,0]-no_rests[row,0])/0.0625)-1\n",
    "                z = np.zeros((n,129))\n",
    "                for i in range(n):\n",
    "                    z[i,0] = no_rests[row,0]+(i+1)*0.0625\n",
    "                data = np.append(data,z,axis=0)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59e0a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Navigation\n",
    "#Put the directory containing the .mxl files here\n",
    "directory = 'C:/Users/Amir/Documents/Graduate School/SEP788_789/Project/music_dataset-main/to_MusicXML/*.mxl'\n",
    "\n",
    "#Initialize some loop variables\n",
    "all_songs = np.empty((0,256,129))\n",
    "song_index = np.empty(0)\n",
    "\n",
    "#Loop through the folder and process each .mxl file, converting to a multi-hot encoded array\n",
    "#Additionally, for each file, shift the key up by a Major 3rd three times to expand dataset\n",
    "#NOTE* This may take a while depending how many files there are\n",
    "for file in glob.glob(directory):\n",
    "    #Load Song\n",
    "    loaded_song = converter.parse(file) #Parse .mxl file and load into python\n",
    "    for j in range(3):\n",
    "        piano_only = getPiano(loaded_song) #Get piano parts only\n",
    "        step_arr = splitToTimesteps(piano_only) #Store in numpy array with 1/16 uniform time step\n",
    "        multiHot_arr = multiHotEncode(step_arr) #Turn pitches into multi-hot encoding\n",
    "        full_song = inferRests(multiHot_arr) #Infer rests from missing timesteps and add them to create uniform array\n",
    "        #Store song in 16 second increments for training (16*0.0625 = 256)\n",
    "        for i in range(0,full_song.shape[0],256):\n",
    "            if(i+256<full_song.shape[0]):\n",
    "                all_songs = np.append(all_songs, full_song[i:i+256,:].reshape(1,256,129),axis=0)\n",
    "                song_index = np.append(song_index,os.path.splitext(os.path.basename(file))[0])\n",
    "        loaded_song = loaded_song.transpose('M3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3142b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape songs to 2D to be stored in a .txt file\n",
    "all_songs_reshaped = all_songs.reshape(-1,129).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae1d3c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing issues with duplicate notes at the same timestep\n",
    "no_time = np.delete(all_songs_reshaped,0,axis=1)\n",
    "wr = np.where(abs(no_time)>1) #Check where notes are not 1 or -1\n",
    "z = np.append(wr[0].reshape(-1,1),wr[1].reshape(-1,1),axis=1)\n",
    "\n",
    "#Loop through notes that are duplicate and replace them\n",
    "for i in range(z.shape[0]):\n",
    "    # Check for note hold but no note-on events, and add a note-hold event\n",
    "    if no_time[z[i,0],z[i,1]] < -1 and no_time[z[i,0]-1,z[i,1]] ==0:\n",
    "        no_time[z[i,0]-1,z[i,1]] = -1\n",
    "    # Check for note-on or note-hold events > 1\n",
    "    if abs(no_time[z[i,0],z[i,1]]) > 1:\n",
    "        no_time[z[i,0],z[i,1]] /= abs(no_time[z[i,0],z[i,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b258f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to songs to a .txt file\n",
    "np.savetxt('C:/Users/Amir/Documents/Graduate School/SEP788_789/Project/music_dataset-main/all_songs_m3.txt',no_time,fmt='%d',delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-new",
   "language": "python",
   "name": "tf-gpu-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
